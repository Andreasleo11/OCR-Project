{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3aecf9",
   "metadata": {},
   "source": [
    "# OCR PROJECT WITH CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70826b",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f1739e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subdir_path, filename))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Convert the image to grayscale\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m img_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Threshold the image to remove any noise or distortion\u001b[39;00m\n\u001b[0;32m     28\u001b[0m img_thresh \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(img_gray, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV \u001b[38;5;241m+\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# CLEANING DATA FOR 1 use , training or testing should be done twice.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Set the path to the original dataset directory\n",
    "original_dir = \"data2/training_data\"\n",
    "\n",
    "# Set the path to the cleaned dataset directory (create if it doesn't exist)\n",
    "cleaned_dir = \"cleandata/train\"\n",
    "if not os.path.exists(cleaned_dir):\n",
    "    os.makedirs(cleaned_dir)\n",
    "\n",
    "# Loop over all subdirectories under the original dataset directory\n",
    "for subdir in os.listdir(original_dir):\n",
    "    subdir_path = os.path.join(original_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop over all images in the current subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                # Load the image\n",
    "                img = cv2.imread(os.path.join(subdir_path, filename))\n",
    "\n",
    "                # Convert the image to grayscale\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Threshold the image to remove any noise or distortion\n",
    "                img_thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "                # Find the contours of the text in the image\n",
    "                contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                # If the image has one contour, save it to the cleaned dataset directory\n",
    "                if len(contours) == 1:\n",
    "                    cleaned_subdir = os.path.join(cleaned_dir, subdir)\n",
    "                    if not os.path.exists(cleaned_subdir):\n",
    "                        os.makedirs(cleaned_subdir)\n",
    "                    cv2.imwrite(os.path.join(cleaned_subdir, filename), img_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f3861",
   "metadata": {},
   "source": [
    "## Data Clean for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1db2e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 44404.png due to corrupted data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Set the path to the original dataset directory\n",
    "original_dir = \"data2/testing_data\"\n",
    "\n",
    "# Set the path to the cleaned dataset directory (create if it doesn't exist)\n",
    "cleaned_dir = \"cleandata/test\"\n",
    "if not os.path.exists(cleaned_dir):\n",
    "    os.makedirs(cleaned_dir)\n",
    "\n",
    "# Loop over all subdirectories under the original dataset directory\n",
    "for subdir in os.listdir(original_dir):\n",
    "    subdir_path = os.path.join(original_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop over all images in the current subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                try:\n",
    "                    # Load the image\n",
    "                    img = cv2.imread(os.path.join(subdir_path, filename))\n",
    "\n",
    "                    # Convert the image to grayscale\n",
    "                    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Threshold the image to remove any noise or distortion\n",
    "                    img_thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "                    # Find the contours of the text in the image\n",
    "                    contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                    # If the image has one contour, save it to the cleaned dataset directory\n",
    "                    if len(contours) == 1:\n",
    "                        cleaned_subdir = os.path.join(cleaned_dir, subdir)\n",
    "                        if not os.path.exists(cleaned_subdir):\n",
    "                            os.makedirs(cleaned_subdir)\n",
    "                        cv2.imwrite(os.path.join(cleaned_subdir, filename), img_thresh)\n",
    "                except:\n",
    "                    print(f\"Skipping {filename} due to corrupted data\")\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee61f40",
   "metadata": {},
   "source": [
    "# Split train to val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f27b76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the path to the cleaned dataset directory\n",
    "dataset_dir = \"cleandata/train\"\n",
    "\n",
    "# Set the path to the output directory\n",
    "output_dir = \"cleandata/validation\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Define the list of classes\n",
    "classes = sorted(os.listdir(dataset_dir))\n",
    "\n",
    "# Initialize the lists for storing the image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop over all subdirectories in the dataset directory\n",
    "for class_index, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, filename)\n",
    "        image_paths.append(image_path)\n",
    "        labels.append(class_index)\n",
    "\n",
    "# Split the data into a training set and a validation set\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Copy the training set and the validation set to the output directory\n",
    "for split_name, split_paths, split_labels in [(\"train\", train_paths, train_labels), \n",
    "                                              (\"val\", val_paths, val_labels)]:\n",
    "    split_dir = os.path.join(output_dir, split_name)\n",
    "    if not os.path.exists(split_dir):\n",
    "        os.makedirs(split_dir)\n",
    "    for image_path, label in zip(split_paths, split_labels):\n",
    "        class_name = classes[label]\n",
    "        dest_dir = os.path.join(split_dir, class_name)\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "        dest_path = os.path.join(dest_dir, os.path.basename(image_path))\n",
    "        with open(image_path, 'rb') as src_file, open(dest_path, 'wb') as dest_file:\n",
    "            dest_file.write(src_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdba271",
   "metadata": {},
   "source": [
    "# Resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50bc1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Set the path to the cleaned dataset directory\n",
    "cleaned_dir = \"cleandata/validation/train\"\n",
    "cleaned_dir1 = \"cleandata/validation/val\"\n",
    "cleaned_dir2 = \"cleandata/test\"\n",
    "\n",
    "# Set the path to the resized dataset directory (create if it doesn't exist)\n",
    "resized_dir = \"cleandata/resized/train\"\n",
    "resized_dir1 = \"cleandata/resized/val\"\n",
    "resized_dir2 =\"cleandata/resized/test\"\n",
    "if not os.path.exists(resized_dir2):\n",
    "    os.makedirs(resized_dir2)\n",
    "\n",
    "# Set the desired size for the images\n",
    "desired_size = (32, 32)\n",
    "\n",
    "# Loop over all subdirectories under the cleaned dataset directory\n",
    "for subdir in os.listdir(cleaned_dir2):\n",
    "    subdir_path = os.path.join(cleaned_dir2, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop over all images in the current subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                # Load the image\n",
    "                img = cv2.imread(os.path.join(subdir_path, filename))\n",
    "\n",
    "                # Resize the image to the desired size\n",
    "                resized_img = cv2.resize(img, desired_size)\n",
    "\n",
    "                # Save the resized image to the resized dataset directory\n",
    "                resized_subdir = os.path.join(resized_dir2, subdir)\n",
    "                if not os.path.exists(resized_subdir):\n",
    "                    os.makedirs(resized_subdir)\n",
    "                cv2.imwrite(os.path.join(resized_subdir, filename), resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01318fa5",
   "metadata": {},
   "source": [
    "## Data Normalization and resizing in train,test, and val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b6a0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (11276, 32, 32, 1)\n",
      "y_train shape: (11276,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "train_dir = \"cleandata/validation/train\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "valid_labels = list(range(10)) + [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "\n",
    "# Loop through all subfolders under the train directory\n",
    "for subdir in os.listdir(train_dir):\n",
    "    if subdir not in valid_labels:\n",
    "        continue\n",
    "    subdir_path = os.path.join(train_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_train.append(img)\n",
    "                y_train.append((subdir) if isinstance(subdir, str) else subdir)  # set the label to the subfolder name (integer or character)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19e1800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (2105, 32, 32, 1)\n",
      "y_test shape: (2105,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "train_dir = \"cleandata/test\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "valid_labels = list(range(10)) + [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "\n",
    "# Loop through all subfolders under the train directory\n",
    "for subdir in os.listdir(train_dir):\n",
    "    if subdir not in valid_labels:\n",
    "        continue\n",
    "    subdir_path = os.path.join(train_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_test.append(img)\n",
    "                y_test.append((subdir) if isinstance(subdir, str) else subdir)  # set the label to the subfolder name (integer or character)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "241ce273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (2819, 32, 32, 1)\n",
      "y_val shape: (2819,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "val_dir = \"cleandata/validation/val\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "valid_labels = list(range(10)) + [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if subdir not in valid_labels:\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_val.append(img)\n",
    "                y_val.append((subdir) if isinstance(subdir, str) else subdir)  # set the label to the subfolder name (integer or character)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817fa29d",
   "metadata": {},
   "source": [
    "## resizing, normalization and labeling process using all data (36 data 0-9 and A to Z) masih fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2894c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4f3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315b8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da12a3f9",
   "metadata": {},
   "source": [
    "## resizing, normalization and labeling process using 0-9 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2488a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4395, 32, 32, 1)\n",
      "y_train shape: (4395, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "val_dir = \"cleandata/validation/train\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "num_classes = 10  # 10 digits only\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if not subdir.isdigit():\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_train.append(img)\n",
    "                label = int(subdir)  # convert the subdirectory name to integer label\n",
    "                y_train.append(label)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a739300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (904, 32, 32, 1)\n",
      "y_test shape: (904, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "val_dir = \"cleandata/test\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "num_classes = 10  # 10 digits only\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if not subdir.isdigit():\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_test.append(img)\n",
    "                label = int(subdir)  # convert the subdirectory name to integer label\n",
    "                y_test.append(label)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf8822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (1099, 32, 32, 1)\n",
      "y_val shape: (1099, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "val_dir = \"cleandata/validation/val\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "num_classes = 10  # 10 digits only\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if not subdir.isdigit():\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_val.append(img)\n",
    "                label = int(subdir)  # convert the subdirectory name to integer label\n",
    "                y_val.append(label)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc6dd8",
   "metadata": {},
   "source": [
    "## resizing, normalization and labeling process using A-Z data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "275cef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (11276, 32, 32, 1)\n",
      "y_train shape: (11276, 26)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "val_dir = \"cleandata/validation/train\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "num_classes = 26  # 26 letters only\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if not subdir.isalpha() or not subdir.isupper():\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_train.append(img)\n",
    "                label = ord(subdir) - ord('A')  # convert character label to integer label\n",
    "                y_train.append(label)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12b9ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (2105, 32, 32, 1)\n",
      "y_test shape: (2105, 26)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "val_dir = \"cleandata/test\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "num_classes = 26  # 26 letters only\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if not subdir.isalpha() or not subdir.isupper():\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_test.append(img)\n",
    "                label = ord(subdir) - ord('A')  # convert character label to integer label\n",
    "                y_test.append(label)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4610226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (2819, 32, 32, 1)\n",
      "y_val shape: (2819, 26)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "val_dir = \"cleandata/validation/val\"\n",
    "img_height, img_width = 32, 32  # define the desired image size\n",
    "num_classes = 26  # 26 letters only\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_height, img_width))\n",
    "    img = img.astype(np.float32) / 255.0  # normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=-1)  # add channel dimension\n",
    "    return img\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "# Loop through all subfolders under the validation directory\n",
    "for subdir in os.listdir(val_dir):\n",
    "    if not subdir.isalpha() or not subdir.isupper():\n",
    "        continue\n",
    "    subdir_path = os.path.join(val_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all images in the current subfolder\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".png\"):\n",
    "                img_path = os.path.join(subdir_path, filename)\n",
    "                img = preprocess_img(img_path)\n",
    "                X_val.append(img)\n",
    "                label = ord(subdir) - ord('A')  # convert character label to integer label\n",
    "                y_val.append(label)\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9091058",
   "metadata": {},
   "source": [
    "### CNN MODEL BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d6de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,986\n",
      "Trainable params: 166,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed83993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (4395, 32, 32, 1)\n",
      "X_val :  (1099, 32, 32, 1)\n",
      "y_train :  (4395, 10)\n",
      "y_val : (1099, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape : \", X_train.shape)\n",
    "print(\"X_val : \", X_val.shape)\n",
    "print(\"y_train : \", y_train.shape)\n",
    "print(\"y_val :\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56394943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 4s 22ms/step - loss: 0.3707 - accuracy: 0.8944 - val_loss: 0.0799 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.0484 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0393 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0577 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 2s 17ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0364 - val_accuracy: 0.9927\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0407 - val_accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 3s 21ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0299 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 3.6463e-04 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 4s 27ms/step - loss: 1.2566e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee31dfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 7ms/step\n",
      "Precision: 99.55%\n",
      "Recall: 99.54%\n",
      "F1 score: 99.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # convert the predicted probabilities to class labels\n",
    "y_true = np.argmax(y_val, axis=1)  # convert the one-hot encoded labels to class labels\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(precision*100))\n",
    "print(\"Recall: {:.2f}%\".format(recall*100))\n",
    "print(\"F1 score: {:.2f}%\".format(f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c3fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.4636101443320513e-05\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b26fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"OCERusingNumber.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
